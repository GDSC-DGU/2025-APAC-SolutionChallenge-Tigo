import 'dart:async';
import 'dart:convert';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:tigo/presentation/view/live_chatbot/LiveMediaManager.dart';
import 'package:tigo/presentation/view/live_chatbot/PCMProcessor.dart';
import 'package:camera/camera.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:web_socket_channel/web_socket_channel.dart';

// ì•± ìƒíƒœ ê´€ë¦¬ìš© enum
enum AppStatus { disconnected, connecting, connected, speaking }

// Gemini ì‘ë‹µ ë©”ì‹œì§€ íŒŒì‹± í´ë˜ìŠ¤
class GeminiLiveResponseMessage {
  String data = "";
  String type = "";
  bool? endOfTurn;

  GeminiLiveResponseMessage(dynamic rawData) {
    // rawDataëŠ” Map<String, dynamic> ë˜ëŠ” JSON String
    Map<String, dynamic> dataMap =
        rawData is String ? jsonDecode(rawData) : rawData;
    endOfTurn = dataMap['serverContent']?['turnComplete'];
    final parts = dataMap['serverContent']?['modelTurn']?['parts'];
    if (dataMap['setupComplete'] == true) {
      type = "SETUP COMPLETE";
    } else if (parts != null && parts.isNotEmpty && parts[0]['text'] != null) {
      data = parts[0]['text'];
      type = "TEXT";
    } else if (parts != null &&
        parts.isNotEmpty &&
        parts[0]['inlineData'] != null) {
      data = parts[0]['inlineData']['data'];
      type = "AUDIO";
    }
  }
}

// Gemini Live API WebSocket ê´€ë¦¬ í´ë˜ìŠ¤
class GeminiLiveAPI {
  final String proxyUrl;
  String projectId;
  final String model;
  final String apiHost;
  late String modelUri;
  List<String> responseModalities = ["AUDIO"];
  String systemInstructions = "";
  late String serviceUrl;
  WebSocketChannel? _ws;
  StreamSubscription? _wsSub;

  // ì½œë°±
  void Function(GeminiLiveResponseMessage message)? onReceiveResponse;
  void Function()? onConnectionStarted;
  void Function(String message)? onErrorMessage;

  GeminiLiveAPI({
    required this.proxyUrl,
    required this.projectId,
    required this.model,
    required this.apiHost,
  }) {
    modelUri =
        "projects/$projectId/locations/us-central1/publishers/google/models/$model";
    serviceUrl =
        "wss://$apiHost/ws/google.cloud.aiplatform.v1beta1.LlmBidiService/BidiGenerateContent";
  }

  void setProjectId(String newProjectId) {
    projectId = newProjectId;
    modelUri =
        "projects/$projectId/locations/us-central1/publishers/google/models/$model";
  }

  Future<void> connect() async {
    await setupWebSocketToService();
  }

  Future<void> disconnect() async {
    await _wsSub?.cancel();
    _ws?.sink.close();
    _ws = null;
    _wsSub = null;
  }

  void sendMessage(Map<String, dynamic> message) {
    if (_ws != null) {
      print('[GeminiLiveAPI] ë©”ì‹œì§€ ì „ì†¡: ${jsonEncode(message)}');
      _ws!.sink.add(jsonEncode(message));
    }
  }

  void _onReceiveMessage(dynamic messageEvent) {
    try {
      print('[GeminiLiveAPI] ë©”ì‹œì§€ ìˆ˜ì‹ : $messageEvent');
      final messageData =
          messageEvent is String ? jsonDecode(messageEvent) : messageEvent;
      final message = GeminiLiveResponseMessage(messageData);
      onReceiveResponse?.call(message);
    } catch (e) {
      print('[GeminiLiveAPI] ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜: $e');
      onErrorMessage?.call('ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜: $e');
    }
  }

  Future<void> setupWebSocketToService() async {
    try {
      print('[GeminiLiveAPI] WebSocket ì—°ê²° ì‹œë„: $proxyUrl');
      _ws = WebSocketChannel.connect(Uri.parse(proxyUrl));
      _wsSub = _ws!.stream.listen(
        _onReceiveMessage,
        onError: (e) {
          print('[GeminiLiveAPI] WebSocket ì˜¤ë¥˜: $e');
          onErrorMessage?.call('WebSocket ì˜¤ë¥˜: $e');
        },
        onDone: () {
          print('[GeminiLiveAPI] WebSocket ì—°ê²° ì¢…ë£Œ');
          onErrorMessage?.call('WebSocket ì—°ê²° ì¢…ë£Œ');
        },
      );
      // ì—°ê²° í›„ ì´ˆê¸° ë©”ì‹œì§€ ì „ì†¡
      print('[GeminiLiveAPI] ì´ˆê¸° ì„¤ì • ë©”ì‹œì§€ ì „ì†¡');
      sendInitialSetupMessages();
      onConnectionStarted?.call();
    } catch (e) {
      print('[GeminiLiveAPI] WebSocket ì—°ê²° ì‹¤íŒ¨: $e');
      onErrorMessage?.call('WebSocket ì—°ê²° ì‹¤íŒ¨: $e');
    }
  }

  void sendInitialSetupMessages() {
    final sessionSetupMessage = {
      'setup': {
        'model': modelUri,
        'generation_config': {'response_modalities': responseModalities},
        'system_instruction': {
          'parts': [
            {'text': systemInstructions},
          ],
        },
      },
    };
    sendMessage(sessionSetupMessage);
  }

  void sendTextMessage(String text) {
    final textMessage = {
      'client_content': {
        'turns': [
          {
            'role': 'user',
            'parts': [
              {'text': text},
            ],
          },
        ],
        'turn_complete': true,
      },
    };
    print('[GeminiLiveAPI] í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡: $text');
    sendMessage(textMessage);
  }

  void sendRealtimeInputMessage(String data, String mimeType) {
    final message = {
      'realtime_input': {
        'media_chunks': [
          {'mime_type': mimeType, 'data': data},
        ],
      },
    };
    sendMessage(message);
  }

  void sendAudioMessage(String base64PCM) {
    print('[GeminiLiveAPI] ì˜¤ë””ì˜¤ ë©”ì‹œì§€ ì „ì†¡');
    sendRealtimeInputMessage(base64PCM, 'audio/pcm');
  }

  void sendImageMessage(String base64Image, {String mimeType = 'image/jpeg'}) {
    print('[GeminiLiveAPI] ì´ë¯¸ì§€ ë©”ì‹œì§€ ì „ì†¡');
    sendRealtimeInputMessage(base64Image, mimeType);
  }
}

class GeminiLiveDemoController {
  // ìƒíƒœ
  AppStatus status = AppStatus.disconnected;

  // ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ë§¤ë‹ˆì €
  late PCMProcessor pcmProcessor;
  LiveAudioOutputManager? audioOutputManager;
  LiveAudioInputManager? audioInputManager;
  LiveVideoManager? videoManager;
  LiveScreenManager? screenManager;

  // ì¹´ë©”ë¼/ë§ˆì´í¬ ë¦¬ìŠ¤íŠ¸
  List<CameraDescription> cameraList = [];
  CameraController? cameraController;
  String? selectedCameraId;
  String? selectedMicId;

  // ì±„íŒ… ë©”ì‹œì§€
  List<String> messages = [];

  // ì½œë°±
  void Function(String message)? onShowDialog;
  void Function()? onStatusChanged;
  void Function(String message)? onNewModelMessage;

  // WebSocket
  WebSocketChannel? _ws;
  StreamSubscription? _wsSub;
  String? _projectId;
  String? _systemInstructions;
  String? _responseModality;

  GeminiLiveDemoController();
  Future<void> init() async {
    // ì¹´ë©”ë¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
    cameraList = await availableCameras();
    // print('ì¹´ë©”ë¼ ëª©ë¡:');
    for (final cam in cameraList) {
      // print('  - 33m[33m${cam.name}[0m (${cam.lensDirection})');
    }
    // í›„ë©´ ì¹´ë©”ë¼ ìš°ì„  ì„ íƒ
    List<CameraDescription> cameras = await availableCameras();

    CameraDescription? backCam = cameras.firstWhere(
      (cam) => cam.lensDirection == CameraLensDirection.back,
      orElse: () => cameras.first,
    );
    // print('ì„ íƒëœ ì¹´ë©”ë¼: 32m[32m${backCam.name}[0m (${backCam.lensDirection})');
    selectedCameraId = backCam.name;
    cameraController = CameraController(backCam, ResolutionPreset.medium);
    try {
      await cameraController!.initialize();
      // print('ì¹´ë©”ë¼ ì´ˆê¸°í™” ì„±ê³µ');
    } catch (e) {
      // print('ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: $e');
      onShowDialog?.call("ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: $e");
      return;
    }
    videoManager = LiveVideoManager(cameraController!);
    // ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    pcmProcessor = PCMProcessor();
    await pcmProcessor.initPlayer();
    audioOutputManager = LiveAudioOutputManager(pcmProcessor);
    audioInputManager = LiveAudioInputManager();
    audioInputManager!.onNewAudioRecordingChunk = (base64Audio) {
      sendAudioMessage(base64Audio);
    };
    // í™”ë©´ê³µìœ  ë§¤ë‹ˆì € (PC/Webë§Œ)
    screenManager = LiveScreenManager();
    // ìƒíƒœ ì½œë°±
    onStatusChanged?.call();
  }

  Future<void> dispose() async {
    // ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ë§¤ë‹ˆì € í•´ì œ
    await pcmProcessor.dispose();
    audioOutputManager = null;
    if (audioInputManager != null) {
      await audioInputManager!.disconnectMicrophone();
      audioInputManager = null;
    }
    if (videoManager != null) {
      await videoManager!.stopLiveStream();
      videoManager = null;
    }
    if (screenManager != null) {
      screenManager!.stopCapture();
      screenManager = null;
    }
    await cameraController?.dispose();
    cameraController = null;
  }

  void setAppStatus(AppStatus newStatus) {
    status = newStatus;
    onStatusChanged?.call();
  }

  // ì—°ê²° ë²„íŠ¼ í´ë¦­
  Future<void> connect(
    String projectId,
    String systemInstructions,
    String responseModality,
  ) async {
    setAppStatus(AppStatus.connecting);
    _projectId = projectId;
    _systemInstructions = systemInstructions;
    _responseModality = responseModality;
    // WebSocket ì—°ê²°
    try {
      final socketBaseUrl = dotenv.get('SOCKET_BASE_URL');
      print('[SOCKET] connect() ì‹œë„: wss://$socketBaseUrl');
      _ws = WebSocketChannel.connect(Uri.parse('wss://$socketBaseUrl'));
      _wsSub = _ws!.stream.listen(
        _onWsMessage,
        onError: (e) {
          print('[SOCKET] WebSocket ì˜¤ë¥˜: $e');
          showDialogWithMessage('WebSocket ì˜¤ë¥˜: $e');
          setAppStatus(AppStatus.disconnected);
        },
        onDone: () {
          print('[SOCKET] WebSocket ì—°ê²° ì¢…ë£Œ');
          setAppStatus(AppStatus.disconnected);
        },
      );

      // // ì—°ê²° í›„ ì¸ì¦/ì„¤ì • ë©”ì‹œì§€ ì „ì†¡ (ì˜ˆì‹œ)
      // _ws!.sink.add(
      //   jsonEncode({
      //     'bearer_token': _accessToken,
      //     'service_url':
      //         'wss://us-central1-aiplatform.googleapis.com/ws/google.cloud.aiplatform.v1beta1.LlmBidiService/BidiGenerateContent',
      //   }),
      // );
      print('[SOCKET] SETUP ìš”ì²­ ì „ì†¡');
      _ws!.sink.add(
        jsonEncode({
          'setup': {
            'model':
                'projects/$_projectId/locations/us-central1/publishers/google/models/gemini-2.0-flash-live-preview-04-09',
            'generation_config': {
              'response_modalities': [_responseModality ?? 'AUDIO'],
            },
            'system_instruction': {
              'parts': [
                {'text': _systemInstructions ?? ''},
              ],
            },
          },
        }),
      );
      print('[SOCKET] SETUP ìš”ì²­ ì „ì†¡ ì™„ë£Œ');
      setAppStatus(AppStatus.connected);
      startAudioInput();
    } catch (e) {
      print('[SOCKET] WebSocket ì—°ê²° ì‹¤íŒ¨: $e');
      showDialogWithMessage('WebSocket ì—°ê²° ì‹¤íŒ¨: $e');
      setAppStatus(AppStatus.disconnected);
    }
  }

  // ì—°ê²° í•´ì œ
  Future<void> disconnect() async {
    print('[SOCKET] disconnect() í˜¸ì¶œ');
    setAppStatus(AppStatus.disconnected);
    await stopAudioInput();
    await stopCameraCapture();
    stopScreenCapture();
    await _wsSub?.cancel();
    _ws?.sink.close();
    _ws = null;
    _wsSub = null;
    print('[SOCKET] disconnect() ì™„ë£Œ');
  }

  // ì˜¤ë””ì˜¤ ì…ë ¥ ì‹œì‘/ì¤‘ì§€
  Future<void> startAudioInput() async {
    await audioInputManager?.connectMicrophone();
  }

  Future<void> stopAudioInput() async {
    await audioInputManager?.disconnectMicrophone();
  }

  // WebSocket ë©”ì‹œì§€ ìˆ˜ì‹  ì²˜ë¦¬
  void _onWsMessage(dynamic rawMessage) {
    print('[SOCKET] ìˆ˜ì‹ (raw): $rawMessage');
    // Gemini ì‘ë‹µ ë©”ì‹œì§€ íŒŒì‹± (ì˜ˆì‹œ)
    try {
      if (rawMessage is List<int>) {
        rawMessage = utf8.decode(rawMessage);
      }
      final data = jsonDecode(rawMessage);
      final parts = data['serverContent']?['modelTurn']?['parts'];
      if (data['setupComplete'] == true) {
        // ì—°ê²° ì™„ë£Œ
        print('[SOCKET] SETUP ì‘ë‹µ ìˆ˜ì‹ : ì—°ê²° ì™„ë£Œ');
        setAppStatus(AppStatus.connected);
      } else if (parts != null &&
          parts.isNotEmpty &&
          parts[0]['text'] != null) {
        print('[SOCKET] TEXT ì‘ë‹µ ìˆ˜ì‹ : ${parts[0]['text']}');
        onReceiveTextResponse(parts[0]['text']);
      } else if (parts != null &&
          parts.isNotEmpty &&
          parts[0]['inlineData'] != null) {
        print('[SOCKET] AUDIO ì‘ë‹µ ìˆ˜ì‹  (inlineData)');
        onReceiveAudioResponse(parts[0]['inlineData']['data']);
      }
    } catch (e) {
      print('[SOCKET] ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜: $e');
      showDialogWithMessage('ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜: $e');
    }
  }

  // ì˜¤ë””ì˜¤ ì‘ë‹µ ìˆ˜ì‹  ì‹œ (Gemini ì‘ë‹µ)
  void onReceiveAudioResponse(String base64Audio) {
    print('â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸[GeminiLiveDemoController] ì˜¤ë””ì˜¤ ì‘ë‹µ ìˆ˜ì‹ ');
    audioOutputManager?.playAudioChunk(base64Audio);
  }

  // í…ìŠ¤íŠ¸ ì‘ë‹µ ìˆ˜ì‹  ì‹œ (Gemini ì‘ë‹µ)
  void onReceiveTextResponse(String text) {
    print('â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸[GeminiLiveDemoController] í…ìŠ¤íŠ¸ ì‘ë‹µ ìˆ˜ì‹ : $text');
    messages.add(">> $text");
    onNewModelMessage?.call(text);
  }

  // ìœ ì € ë©”ì‹œì§€ ì „ì†¡
  void sendUserMessage(String text) {
    print('[GeminiLiveDemoController] ìœ ì € ë©”ì‹œì§€ ì „ì†¡: $text');
    messages.add("User: $text");
    sendTextMessage(text);
  }

  // Gemini APIë¡œ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡
  void sendTextMessage(String text) {
    if (_ws != null) {
      print('[SOCKET] í…ìŠ¤íŠ¸ ìš”ì²­ ì „ì†¡: $text');
      print('[GeminiLiveDemoController] Gemini APIë¡œ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡: $text');
      _ws!.sink.add(
        jsonEncode({
          'client_content': {
            'turns': [
              {
                'role': 'user',
                'parts': [
                  {'text': text},
                ],
              },
            ],
            'turn_complete': true,
          },
        }),
      );
      print('[SOCKET] í…ìŠ¤íŠ¸ ìš”ì²­ ì „ì†¡ ì™„ë£Œ');
    }
  }

  // Gemini APIë¡œ ì˜¤ë””ì˜¤ ë©”ì‹œì§€ ì „ì†¡
  void sendAudioMessage(String base64Audio) {
    if (_ws != null) {
      print('[SOCKET] ì˜¤ë””ì˜¤ ìš”ì²­ ì „ì†¡');
      print('[GeminiLiveDemoController] Gemini APIë¡œ ì˜¤ë””ì˜¤ ë©”ì‹œì§€ ì „ì†¡');
      _ws!.sink.add(
        jsonEncode({
          'realtime_input': {
            'media_chunks': [
              {'mime_type': 'audio/pcm', 'data': base64Audio},
            ],
          },
        }),
      );
      print('[SOCKET] ì˜¤ë””ì˜¤ ìš”ì²­ ì „ì†¡ ì™„ë£Œ');
    }
  }

  // ì´ë¯¸ì§€ ë©”ì‹œì§€ ì „ì†¡ (ì¹´ë©”ë¼/í™”ë©´ê³µìœ )
  void sendImageMessage(String base64Image) {
    if (_ws != null) {
      print('[SOCKET] ì´ë¯¸ì§€ ìš”ì²­ ì „ì†¡');
      print('[GeminiLiveDemoController] ì´ë¯¸ì§€ ë©”ì‹œì§€ ì „ì†¡');
      _ws!.sink.add(
        jsonEncode({
          'realtime_input': {
            'media_chunks': [
              {'mime_type': 'image/jpeg', 'data': base64Image},
            ],
          },
        }),
      );
      print('[SOCKET] ì´ë¯¸ì§€ ìš”ì²­ ì „ì†¡ ì™„ë£Œ');
    }
  }

  // ì¹´ë©”ë¼ í”„ë ˆì„ ì½œë°± ë“±ë¡
  void setOnNewVideoFrame(void Function(String base64Image) onNewFrame) {
    int lastSentMillis = 0;
    videoManager?.onNewFrame = (b64Image) {
      final now = DateTime.now().millisecondsSinceEpoch;
      if (now - lastSentMillis >= 5000) {
        print('[GeminiLiveDemoController] ì¹´ë©”ë¼ í”„ë ˆì„ ì½œë°± ë°œìƒ (5ì´ˆ ì œí•œ)');
        sendImageMessage(b64Image);
        onNewFrame(b64Image);
        lastSentMillis = now;
      } else {
        // print('[GeminiLiveDemoController] ì´ë¯¸ì§€ ì „ì†¡ ìŠ¤í‚µ (5ì´ˆ ë¯¸ë§Œ)');
      }
    };
  }

  // í™”ë©´ê³µìœ  í”„ë ˆì„ ì½œë°± ë“±ë¡
  void setOnNewScreenFrame(void Function(String base64Image) onNewFrame) {
    screenManager?.onNewFrame = (b64Image) {
      print('[GeminiLiveDemoController] í™”ë©´ê³µìœ  í”„ë ˆì„ ì½œë°± ë°œìƒ');
      sendImageMessage(b64Image);
      onNewFrame(b64Image);
    };
  }

  // ì¹´ë©”ë¼/ë§ˆì´í¬ ì„ íƒ
  Future<void> selectCamera(String cameraId) async {
    final cam = cameraList.firstWhere(
      (c) => c.name == cameraId,
      orElse: () => cameraList.first,
    );
    selectedCameraId = cam.name;
    await cameraController?.dispose();
    cameraController = CameraController(cam, ResolutionPreset.medium);
    await cameraController!.initialize();
    videoManager = LiveVideoManager(cameraController!);
  }

  void selectMic(String micId) {
    selectedMicId = micId;
    // ì‹¤ì œ ë§ˆì´í¬ ë³€ê²½ì€ í”Œë«í¼ë³„ ì¶”ê°€ êµ¬í˜„ í•„ìš”
  }

  // ì¹´ë©”ë¼/í™”ë©´ê³µìœ  ì‹œì‘/ì¤‘ì§€
  Future<void> startCameraCapture() async {
    screenManager?.stopCapture();
    await videoManager?.startLiveStream();
  }

  Future<void> stopCameraCapture() async {
    await videoManager?.stopLiveStream();
  }

  void startScreenCapture() {
    videoManager?.stopLiveStream();
    screenManager?.startCapture();
  }

  void stopScreenCapture() {
    screenManager?.stopCapture();
  }

  // ë‹¤ì´ì–¼ë¡œê·¸ í‘œì‹œ
  void showDialogWithMessage(String message) {
    onShowDialog?.call(message);
  }
}
